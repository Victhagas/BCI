{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CyberLab Challenge",
      "provenance": [],
      "authorship_tag": "ABX9TyM3iw9QVVIC6rBh6XQFQPYp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victhagas/MNIST-Project/blob/main/MNIST_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsI4kWaqHGVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92c06fa-ffc1-45ec-d896-27b48de4650b"
      },
      "source": [
        "# Desafio! Criar um classificador que consiga diferenciar os números 0 e 5\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "\n",
        "import fastbook\n",
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import tensorflow        as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from fastbook          import *\n",
        "\n",
        "fastbook.setup_book()\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 186 kB 41.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 308 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7zrN9IVHnJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "97f2ac83-3ac6-4504-f90a-40a29df332e5"
      },
      "source": [
        "# Pegar os arquivos de imagem correspondentes aos números 0 e 5 do dataset MNIST.\n",
        "# Getting the image files corresponding to the numbers 0 and 5 from the MNIST dataset.\n",
        "\n",
        "path = untar_data(URLs.MNIST) # Como o arquivo original do Dataset é comprimido, é necessário usar o untar_data.\n",
        "Path.BASE_PATH = path         # As the original Dataset file is compressed, it is necessary to use untar_data."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoBK6eYNJl3Z",
        "outputId": "bbd463b0-8b91-4151-f8ab-c11057dbd9a8"
      },
      "source": [
        "path.ls() # Usar o .ls para ver os dados contidos no dataset MNIST.\n",
        "          # Using .ls to see the data from the MNIST dataset."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkVMN1P6LY7a"
      },
      "source": [
        "zeroes_train = (path/'training/0').ls() # Armazenando os dados de treino correspondentes ao numeral em uma variável (i.e: zero)\n",
        "fives_train  = (path/'training/5').ls() # Storing the training data corresponding to the numeral in a variable (i.e: five)\n",
        "\n",
        "zeroes_test = (path/'testing/0').ls()   # Mesmo caso das variáveis acima, porém com os dados de teste\n",
        "fives_test  = (path/'testing/5').ls()   # Same thing as above, but using the variable to save the testing data "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFgmJ69UQZ--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ac280b-a670-4a87-df6e-5536bf2e28b2"
      },
      "source": [
        "train_0 = torch.stack([tensor(Image.open(i)) for i in zeroes_train]).float()/255 # list comprehension para transformar todas as imagens de treino em \n",
        "# tensores. Após isso, juntar todos os novos tensores em um só (torch.stack). Por fim, deixar cada pixel desse novo tensor em escala 0~1. \n",
        "\n",
        "train_5 = torch.stack([tensor(Image.open(i)) for i in fives_train ]).float()/255 # list comprehension to transform all training images into\n",
        "# tensors. After that, join all the new tensors into one (torch.stack). Finally, let each pixel of this new tensor in 0~1 scale. \n",
        "\n",
        "test_0  = torch.stack([tensor(Image.open(i)) for i in zeroes_test ]).float()/255 # Mesma ideia da variável anterior, porém com os as imagens de teste \n",
        "\n",
        "test_5  = torch.stack([tensor(Image.open(i)) for i in fives_test  ]).float()/255 # Same idea from above, but using the testing images. \n",
        "\n",
        "print(train_0.shape, train_5.shape) # Checando os tamanhos das nossas novas variaveis! \n",
        "print(test_0.shape, test_5.shape);  # Checking the shapes of our new born variables!"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5923, 28, 28]) torch.Size([5421, 28, 28])\n",
            "torch.Size([980, 28, 28]) torch.Size([892, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgsAYL0XWkzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034c3ba9-9be8-47a0-edd4-2d2ffccd7a01"
      },
      "source": [
        "train_x = torch.cat([train_0, train_5]).view(-1, 28*28) # Concatenando as duas variáveis de treino e mudando o tamanho do tensor.\n",
        "train_y = tensor([1]*len(zeroes_train) + [0]*len(fives_train)).unsqueeze(1) # Rotulando cada imagem do dataset e modelando o tensor\n",
        "\n",
        "dset = list(zip(train_x,train_y)) # Criando um dataset combinando a função zip + list, nos dados de treino.\n",
        "x,y  = dset[0]\n",
        "\n",
        "test_x    = torch.cat([test_0, test_5]).view(-1, 28*28) # Concatenating the two training variables and changing the tensor's shape.\n",
        "test_y    = tensor([1]*len(test_0) + [0]*len(test_5)).unsqueeze(1) # Labeling each image and reshaping the tensor\n",
        "\n",
        "test_dset = list(zip(test_x,test_y)) # Creating a dataset, by combining zip and list functions, in the testing data. \n",
        "\n",
        "train_x.shape,train_y.shape # Checking some of our new tensors!!"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([11344, 784]), torch.Size([11344, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e1d6NQDYmjD"
      },
      "source": [
        "def _parameters(size, std=1.0): # Primeiro passo para podermos inicializar os pesos e bias futuramente.\n",
        "                                # The first step to initialize the weights, randomly, for every pixel.\n",
        "\n",
        "  return (torch.randn(size)*std).requires_grad_()\n",
        "\n",
        "def mult_mat(xn): # A equação fundamental de redes neurais, batch*weights + bias. Com o * sendo uma multiplicação matricial.\n",
        "                  # The fundamental equation, batch*weights + bias. With * being a matricial multiplication.\n",
        "  \n",
        "  return xn@weights + bias\n",
        "  \n",
        "def loss_function(predictions, targets): # Essa função vai medir a distancia entre o valor da predição do seu alvo, e limitar a predição à ser entre 0 e 1\n",
        "    predictions = predictions.sigmoid()  # This function will measure the distance of the predictions from the real values, and limit the predictions (0~1)\n",
        "    \n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean() # Medindo a distancia da predição ao seu alvo.    \n",
        "                                                                      # Measuring the distance of the predictions from its target.\n",
        "\n",
        "def calc_grad(xn, yn, model): # Como o nome diz, essa função é responsavel por calcular o gradiente, e para isso, utiliza-se a loss function.\n",
        "    preds = model(xn)         # As the name says, this definition will calculate the gradient value, by using the loss function.\n",
        "    loss  = loss_function(preds, yn) \n",
        "    loss.backward()           # loss.backward() calcula a taxa de variação (dloss/dx) para cada parametro em x. \n",
        "                              # loss.backward() computes dloss/dx for every parameter x.\n",
        "\n",
        "weights = _parameters((28*28,1)) # Inicializando os Pesos (weights), que irão de fato fazer o aprendizado de máquina \n",
        "bias    = _parameters(1)         # Initializing the bias, which are going to do the machine learning.\n",
        "\n",
        "dload      = DataLoader(     dset, batch_size=256) # O DataLoades promove uma iteração entre o dataset predefinido e as batches.\n",
        "test_dload = DataLoader(test_dset, batch_size=256) # the DataLoader configurs an interation of the dataset over the batches.\n",
        "\n",
        "batch   = train_x[:4]       # Tamanho das mini-batches.\n",
        "                            # Size of the mini-batches.\n",
        "\n",
        "predict = mult_mat(batch)   # Usando a definição da função fundamental com a batch setada acima como input.\n",
        "                            # Using the definition of the fundamental function, with the batch set above as input.\n",
        "\n",
        "loss    = loss_function(predict, train_y[:4]) # Armazenando a definição loss_function já com inputs especificos em uma variável, para facilitar.\n",
        "                                              # Saving the loss_function definition in a variable, to make things easier.\n",
        "\n",
        "xn,yn   = first(dload)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdG4b0FLmvVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27efef55-f617-4f6e-941b-9401fc7afde0"
      },
      "source": [
        "def training_epochs(model, learn_r, _parameters): # Definição que de fato faz o treinamento, usando todos os parâmetros setados acima\n",
        "                                                  # Definition that does the training over the epochs, by using all parameters set above\n",
        "\n",
        "    for xn,yn in dload:                           \n",
        "        calc_grad(xn, yn, model)\n",
        "        for i in _parameters:\n",
        "            i.data = i.data - i.grad*learn_r # Dentro da iteração no DataLoad, ocorre outra iteração que atualiza os dados usando learning ratio.\n",
        "                                             # Inside the DataLoad for loop, occurs other iteration loop that update the data by using the learning ratio.\n",
        "            i.grad.zero_()                   \n",
        "\n",
        "def batch_acc(xn, yn):                 # Definição para corrigir e efetuar a média das predições, além de limitar o valor entre 0 e 1.\n",
        "                                       # Definition that corrects and does the mean of predictions, and fix its limits between 0 and 1.\n",
        "    preds   = xn.sigmoid()                    \n",
        "    correct = (preds>0.5) == yn\n",
        "    return correct.float().mean()\n",
        "\n",
        "def testing_epochs(model):             # Definição para juntar a batch_acc (definição acima) para todas as batches.\n",
        "                                       # Definition that gather all batches accuracy.\n",
        "    accs = [batch_acc(model(xn), yn) for xn,yn in test_dload]\n",
        "    return round(torch.stack(accs).mean().item(), 4)\n",
        "  \n",
        "testing_epochs(mult_mat)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.482"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMjNS5xGqJEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e508dc-494d-42e1-b36e-677419d960d8"
      },
      "source": [
        "learn_r = 1.  \n",
        "_parameters = weights,bias\n",
        "\n",
        "for i in range(30):                     # Setando a quantidade de sessões de treinamento o classificador receberá.\n",
        "                                        # For loop to set the training sections' quantity the classifier will receive.\n",
        "  training_epochs(mult_mat,learn_r,_parameters)   \n",
        "  print(testing_epochs(mult_mat), end=' ')\n",
        "testing_epochs(mult_mat)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5418 0.6473 0.7757 0.8499 0.8993 0.9281 0.9438 0.9564 0.9633 0.9677 0.9717 0.9731 0.9761 0.9775 0.979 0.9805 0.9824 0.9834 0.9839 0.9839 0.9863 0.9863 0.9863 0.9868 0.9868 0.9868 0.9863 0.9863 0.9868 0.9873 "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9873"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}